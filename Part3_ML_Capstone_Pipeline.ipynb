{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: The ML Capstone Pipeline\n",
        "\n",
        "**Objective**: Build, train, and track a complete, production-style ML pipeline using MLlib and MLflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Import required libraries\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "import mlflow\n",
        "\n",
        "# Load TPC-H datasets (built into Databricks)\n",
        "customers_df = spark.read.parquet(\"/databricks-datasets/tpch/data-001/customer.parquet\")\n",
        "orders_df = spark.read.parquet(\"/databricks-datasets/tpch/data-001/orders.parquet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module 3.1: Feature Engineering Pipeline\n",
        "\n",
        "**Goal**: Convert raw data into ML-ready \"features\" vectors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for ML - join customers with orders (simple!)\n",
        "ml_data = customers_df.join(\n",
        "    orders_df,\n",
        "    customers_df.c_custkey == orders_df.o_custkey,\n",
        "    \"inner\"\n",
        ").dropna(subset=[\"o_totalprice\", \"c_acctbal\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract simple time features from order date\n",
        "ml_data = ml_data.withColumn(\"month\", month(col(\"o_orderdate\")))\n",
        "\n",
        "# Show the data we'll use for ML\n",
        "ml_data.select(\n",
        "    \"c_acctbal\", \"c_mktsegment\", \"o_totalprice\", \"month\"\n",
        ").show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1: StringIndexer (for categorical columns)\n",
        "\n",
        "Converts categorical text into numeric indices that ML models can use.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Index the one categorical column we need\n",
        "market_segment_indexer = StringIndexer(\n",
        "    inputCol=\"c_mktsegment\",\n",
        "    outputCol=\"market_segment_index\"\n",
        ")\n",
        "\n",
        "# Fit and transform (learns the mapping, then applies it)\n",
        "ml_data = market_segment_indexer.fit(ml_data).transform(ml_data)\n",
        "\n",
        "ml_data.select(\"c_mktsegment\", \"market_segment_index\").show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 2: VectorAssembler (combine all features)\n",
        "\n",
        "Combines all feature columns into a single vector that ML models require.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define feature columns (just 3 features - keep it simple!)\n",
        "feature_columns = [\n",
        "    \"c_acctbal\",\n",
        "    \"market_segment_index\",\n",
        "    \"month\"\n",
        "]\n",
        "\n",
        "# Create VectorAssembler (combines features into one vector)\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_columns,\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Transform data\n",
        "ml_data_vectorized = assembler.transform(ml_data)\n",
        "\n",
        "# Show the features vector and label\n",
        "ml_data_vectorized.select(\"features\", \"o_totalprice\").show(5, truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Build the Pipeline\n",
        "\n",
        "A Pipeline chains multiple transformers together for easy reuse.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple pipeline\n",
        "pipeline = Pipeline(stages=[\n",
        "    market_segment_indexer,\n",
        "    assembler\n",
        "])\n",
        "\n",
        "print(\"‚úì Feature engineering pipeline created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module 3.2: Model Training & MLflow\n",
        "\n",
        "**Goal**: Train a model to predict ride duration and track it automatically.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare final dataset with label (predicting order total - regression)\n",
        "model_data = ml_data_vectorized.select(\"features\", col(\"o_totalprice\").alias(\"label\"))\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "train_df, test_df = model_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "print(f\"Training set: {train_df.count():,} orders\")\n",
        "print(f\"Test set: {test_df.count():,} orders\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add RandomForestRegressor to the pipeline\n",
        "rf = RandomForestRegressor(\n",
        "    featuresCol=\"features\",\n",
        "    labelCol=\"label\",\n",
        "    numTrees=10,\n",
        "    maxDepth=5,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Complete pipeline: feature engineering + model\n",
        "full_pipeline = Pipeline(stages=[\n",
        "    market_segment_indexer,\n",
        "    assembler,\n",
        "    rf\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ MLflow: Automatic Experiment Tracking\n",
        "\n",
        "MLflow automatically tracks:\n",
        "- Model parameters\n",
        "- Training metrics\n",
        "- Model artifacts\n",
        "- Code version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for training (just the features we need)\n",
        "train_data = ml_data.select(\n",
        "    \"c_acctbal\",\n",
        "    \"c_mktsegment\",\n",
        "    \"month\",\n",
        "    col(\"o_totalprice\").alias(\"label\")\n",
        ")\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "train_df, test_df = train_data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Train model with MLflow tracking\n",
        "with mlflow.start_run(run_name=\"TPCH_Order_Value_Model\"):\n",
        "    # Fit the pipeline (handles all transformations + training)\n",
        "    print(\"‚è≥ Training model...\")\n",
        "    pipeline_model = full_pipeline.fit(train_df)\n",
        "    \n",
        "    # Make predictions\n",
        "    predictions = pipeline_model.transform(test_df)\n",
        "    \n",
        "    # Calculate RMSE\n",
        "    from pyspark.ml.evaluation import RegressionEvaluator\n",
        "    evaluator = RegressionEvaluator(\n",
        "        labelCol=\"label\",\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"rmse\"\n",
        "    )\n",
        "    rmse = evaluator.evaluate(predictions)\n",
        "    \n",
        "    # Log to MLflow\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.spark.log_model(pipeline_model, \"my_tpch_order_value_model\")\n",
        "    \n",
        "    print(f\"‚úì Model trained! RMSE: {rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéâ \"Wow\" Moment: View Your Experiment\n",
        "\n",
        "**Check the Experiments tab**:\n",
        "1. Click **Experiments** in the left sidebar (Databricks)\n",
        "2. Find your run \"TPCH_Order_Value_Model\"\n",
        "3. See your tracked metrics and model artifact!\n",
        "\n",
        "This is production-grade ML tracking - automatically!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module 3.3: Save & Load\n",
        "\n",
        "**Goal**: Prove the pipeline is a real, reusable \"artifact.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the latest run ID from MLflow\n",
        "runs = mlflow.search_runs()\n",
        "latest_run = runs.iloc[0]\n",
        "run_id = latest_run['run_id']\n",
        "print(f\"Run ID: {run_id}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model from MLflow\n",
        "model_uri = f\"runs:/{run_id}/my_tpch_order_value_model\"\n",
        "loaded_model = mlflow.spark.load_model(model_uri)\n",
        "\n",
        "print(\"‚úì Model loaded from MLflow!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply model to new data (needs raw features)\n",
        "new_data = ml_data.select(\n",
        "    \"c_acctbal\",\n",
        "    \"c_mktsegment\",\n",
        "    \"month\",\n",
        "    col(\"o_totalprice\").alias(\"label\")\n",
        ").limit(100)\n",
        "\n",
        "predictions = loaded_model.transform(new_data)\n",
        "\n",
        "# Show predictions\n",
        "predictions.select(\"label\", \"prediction\").show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üéØ Key Takeaways\n",
        "\n",
        "1. **Feature Engineering**: Transform raw data into ML features\n",
        "2. **Pipelines**: Chain transformations for reusability\n",
        "3. **MLflow**: Automatic experiment tracking and model versioning\n",
        "4. **Model Persistence**: Save and load models for production use\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
