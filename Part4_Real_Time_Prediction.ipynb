{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 4: Real-Time Prediction\n",
        "\n",
        "**Objective**: Use our saved batch model to score a live simulated stream. This provides the \"wow\" moment with zero setup.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: Import required libraries\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "import mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module 4.1: The \"Live Order\" Simulator\n",
        "\n",
        "**Goal**: Use the rate source (a built-in simulator) to manufacture a new stream of orders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the trained model from Part 3\n",
        "runs = mlflow.search_runs()\n",
        "latest_run = runs.iloc[0]\n",
        "run_id = latest_run['run_id']\n",
        "\n",
        "model_uri = f\"runs:/{run_id}/my_tpch_order_value_model\"\n",
        "loaded_model = mlflow.spark.load_model(model_uri)\n",
        "\n",
        "print(f\"âœ“ Model loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a Simulated Stream\n",
        "\n",
        "The `rate` source generates a stream of timestamps at a specified rate - perfect for simulating live data!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create rate stream (generates timestamps)\n",
        "rate_stream = spark.readStream \\\n",
        "    .format(\"rate\") \\\n",
        "    .option(\"rowsPerSecond\", 1) \\\n",
        "    .load()\n",
        "\n",
        "rate_stream.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform rate stream into order data (simple simulation)\n",
        "orders_stream = rate_stream.select(\n",
        "    col(\"timestamp\").alias(\"order_time\"),\n",
        "    # Simulate the 3 features our model needs\n",
        "    (rand() * 12 + 1).cast(\"int\").alias(\"month\"),\n",
        "    (rand() * 100000 - 1000).cast(\"double\").alias(\"c_acctbal\"),\n",
        "    # Market segment\n",
        "    when(rand() > 0.8, \"AUTOMOBILE\")\n",
        "    .when(rand() > 0.6, \"BUILDING\")\n",
        "    .when(rand() > 0.4, \"MACHINERY\")\n",
        "    .when(rand() > 0.2, \"HOUSEHOLD\")\n",
        "    .otherwise(\"FURNITURE\").alias(\"c_mktsegment\")\n",
        ")\n",
        "\n",
        "orders_stream.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module 4.2: Apply Model & Display Live\n",
        "\n",
        "**Goal**: See live predictions in the notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Features for the Model\n",
        "\n",
        "We need to apply the same feature engineering pipeline that was used during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The loaded model is a full pipeline that includes feature engineering!\n",
        "# It will automatically apply StringIndexer and VectorAssembler\n",
        "# We just need to provide the raw features matching the pipeline input\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Apply Model to Stream\n",
        "\n",
        "The model can be applied directly to streaming DataFrames!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply model to stream (pipeline handles feature engineering automatically!)\n",
        "predictions_stream = loaded_model.transform(orders_stream)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Display Live Predictions\n",
        "\n",
        "Use `display()` (Databricks) or write to console/sink for live predictions in Jupyter notebooks!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display live predictions\n",
        "# In Databricks: use display() for live updates\n",
        "# In local: use console sink\n",
        "query = predictions_stream.select(\n",
        "    \"order_time\",\n",
        "    \"c_mktsegment\",\n",
        "    \"c_acctbal\",\n",
        "    \"prediction\"\n",
        ").writeStream \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .format(\"console\") \\\n",
        "    .start()\n",
        "\n",
        "# In Databricks, use: display(predictions_stream.select(\"order_time\", \"c_mktsegment\", \"c_acctbal\", \"prediction\"))\n",
        "\n",
        "print(\"Streaming started! Check console for predictions.\")\n",
        "print(\"To stop: query.stop()\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Live Predictions!\n",
        "\n",
        "**What you're seeing**:\n",
        "- A stream generating predictions every second\n",
        "- Each row is a new order being scored in real-time\n",
        "- The `prediction` column shows predicted order value\n",
        "\n",
        "**In production**: Real data from Kafka/Kinesis, running 24/7\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸŽ¯ Key Takeaways\n",
        "\n",
        "1. **Streaming**: Use `rate` for simulation, Kafka/Kinesis for production\n",
        "2. **Models**: ML models work seamlessly with streaming DataFrames\n",
        "3. **Real-Time**: Same batch model scores live data\n",
        "4. **Display**: Use `display()` in Databricks for live updates\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ’¡ Production Considerations\n",
        "\n",
        "**For real production streaming**:\n",
        "- Use Kafka, Kinesis, or Event Hub as source\n",
        "- Write predictions to Delta Lake or database\n",
        "- Enable checkpointing for fault tolerance\n",
        "- Monitor with Spark UI and alerting\n",
        "\n",
        "**Example production code**:\n",
        "```python\n",
        "query = predictions_stream.writeStream \\\n",
        "    .format(\"delta\") \\\n",
        "    .option(\"checkpointLocation\", \"/checkpoint/path\") \\\n",
        "    .outputMode(\"append\") \\\n",
        "    .start(\"dbfs:/predictions/\")\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop the streaming query when done\n",
        "# Uncomment the line below to stop the stream\n",
        "query.stop()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
